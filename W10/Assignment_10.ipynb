{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4fb53c5",
   "metadata": {},
   "source": [
    "# 1.Graph classification task\n",
    "# Dataset: Molecular_Sample.csv\n",
    "\n",
    "### 1.1. Extract graph features with eigenvector centrality, Katz centrality, Laplacian centrality\n",
    "### 1.2.Train model (SVM/MLP) with graph features as concatenation of above graph features,  with test_size = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a477d87",
   "metadata": {},
   "source": [
    "# 2. Graph classification task\n",
    "# Dataset: Molecular_Sample.csv, load p_np column as label (y)\n",
    "\n",
    "### Train model (SVM/MLP) with graph features as graphlet kernel (X) from practice code W7 with test_size = 0.3, with graphlets kernel size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b97d266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphlet Kernel\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "def compute_graphlet_counts(G, k):\n",
    "    \"\"\"\n",
    "    Compute the counts of k-node graphlets in the given graph.\n",
    "\n",
    "    Parameters:\n",
    "        G (networkx.Graph): The input graph.\n",
    "        k (int): The size of the graphlets to count.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the counts of k-node graphlets.\n",
    "    \"\"\"\n",
    "    graphlet_counts = {graphlet: 0 for graphlet in range(1, k+1)}\n",
    "\n",
    "    for node in G.nodes():\n",
    "    # Generate the induced subgraph with node and its neighbors\n",
    "        subgraph_nodes = [node] + list(G.neighbors(node))\n",
    "        subgraph = G.subgraph(subgraph_nodes)\n",
    "\n",
    "        # Count the occurrences of k-node graphlets in the subgraph\n",
    "        for graphlet_size in range(1, k+1):\n",
    "            for subgraph_nodes_subset in combinations(subgraph_nodes, graphlet_size):\n",
    "                if G.subgraph(subgraph_nodes_subset).number_of_nodes() == graphlet_size:\n",
    "                    graphlet_counts[graphlet_size] += 1\n",
    "\n",
    "    return graphlet_counts #Use graphlet_counts as feature vector\n",
    "\n",
    "#Change molecule to graph\n",
    "def mol_to_nx_graph(mol):\n",
    "    \"\"\"\n",
    "    Convert RDKit molecule to NetworkX graph.\n",
    "\n",
    "    Parameters:\n",
    "        mol (RDKit molecule): The input molecule.\n",
    "\n",
    "    Returns:\n",
    "        networkx.Graph: The NetworkX graph representation of the molecule.\n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Add nodes for atoms\n",
    "    for atom in mol.GetAtoms():\n",
    "        G.add_node(atom.GetIdx(), atomic_num=atom.GetAtomicNum())\n",
    "\n",
    "    # Add edges for bonds\n",
    "    for bond in mol.GetBonds():\n",
    "        G.add_edge(bond.GetBeginAtomIdx(), bond.GetEndAtomIdx(), bond_type=bond.GetBondType())\n",
    "\n",
    "    return G\n",
    "\n",
    "# Try to convert molecules to NetworkX graphs\n",
    "# Compute the graph kernel for each molecule\n",
    "# After that, we can train a machine learning model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97100766",
   "metadata": {},
   "source": [
    "# 3. Graph classification task\n",
    "# Dataset: Molecular_Sample.csv, load p_np column as label (y)\n",
    "\n",
    "### Train model (SVM/MLP) with graph features as random walk kernel (X) from practice code W7 with test_size = 0.3, walk_length = 4, num_walks = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91ce1b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def random_walk(graph, walk_length):\n",
    "    \"\"\"\n",
    "    Perform a random walk of a given length on a graph starting from a random node.\n",
    "\n",
    "    Parameters:\n",
    "        graph (networkx.Graph): The input graph.\n",
    "        walk_length (int): The length of the random walk.\n",
    "\n",
    "    Returns:\n",
    "        tuple: The sequence of nodes in the random walk.\n",
    "    \"\"\"\n",
    "    node = random.choice(list(graph.nodes()))\n",
    "    walk = [node]\n",
    "    for _ in range(walk_length - 1):\n",
    "        neighbors = list(graph.neighbors(node))\n",
    "        if neighbors:\n",
    "            node = random.choice(neighbors)\n",
    "            walk.append(node)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return tuple(walk)\n",
    "\n",
    "def random_walk_self_kernel(graph, walk_length=2, num_walks=20):\n",
    "    \"\"\"\n",
    "    Calculate the random walk kernel for a single graph.\n",
    "\n",
    "    Parameters:\n",
    "        graph (networkx.Graph): The input graph.\n",
    "        walk_length (int): The length of the random walk.\n",
    "        num_walks (int): The number of random walks to perform.\n",
    "\n",
    "    Returns:\n",
    "        float: The normalized random walk kernel value for the graph.\n",
    "    \"\"\"\n",
    "    walk_counts = {}\n",
    "\n",
    "    for _ in range(num_walks):\n",
    "        walk = random_walk(graph, walk_length)\n",
    "        if walk in walk_counts:\n",
    "            walk_counts[walk] += 1\n",
    "        else:\n",
    "            walk_counts[walk] = 1\n",
    "\n",
    "    # Calculate the kernel value based on the counts of identical walks\n",
    "    kernel_value = sum(count ** 2 for count in walk_counts.values())\n",
    "    \n",
    "    # Normalize the kernel value\n",
    "    kernel_value /= num_walks\n",
    "\n",
    "    return kernel_value\n",
    "\n",
    "# Same with the graphlet kernel instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c967ba0",
   "metadata": {},
   "source": [
    "# 4. K-means Clustering task\n",
    "# Dataset: Molecular_Sample.csv\n",
    "\n",
    "### Perfrom k-means clustering with Weisfeiler-Lehman hashes, number of cluster = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c022bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for hashing graphs to strings\n",
    "\"\"\"\n",
    "Functions for hashing graphs to strings.\n",
    "Isomorphic graphs should be assigned identical hashes.\n",
    "For now, only Weisfeiler-Lehman hashing is implemented.\n",
    "\"\"\"\n",
    "from hashlib import blake2b\n",
    "\n",
    "def _hash_label(label, digest_size):\n",
    "    return blake2b(label.encode(\"ascii\"), digest_size=digest_size).hexdigest()\n",
    "\n",
    "def _init_node_labels(G, edge_attr, node_attr):\n",
    "    if node_attr:\n",
    "        return {u: str(dd[node_attr]) for u, dd in G.nodes(data=True)}\n",
    "    elif edge_attr:\n",
    "        return {u: \"\" for u in G}\n",
    "    else:\n",
    "        return {u: str(deg) for u, deg in G.degree()}\n",
    "\n",
    "def _neighborhood_aggregate(G, node, node_labels, edge_attr=None):\n",
    "    \"\"\"\n",
    "    Compute new labels for given node by aggregating\n",
    "    the labels of each node's neighbors.\n",
    "    \"\"\"\n",
    "    label_list = []\n",
    "    for nbr in G.neighbors(node):\n",
    "        prefix = \"\" if edge_attr is None else str(G[node][nbr][edge_attr])\n",
    "        label_list.append(prefix + node_labels[nbr])\n",
    "    return node_labels[node] + \"\".join(sorted(label_list))\n",
    "\n",
    "def weisfeiler_lehman_graph_hash(\n",
    "    G, edge_attr=None, node_attr=None, iterations=3, digest_size=16\n",
    "):\n",
    "    def weisfeiler_lehman_step(G, labels, edge_attr=None):\n",
    "        \"\"\"\n",
    "        Apply neighborhood aggregation to each node\n",
    "        in the graph.\n",
    "        Computes a dictionary with labels for each node.\n",
    "        \"\"\"\n",
    "        new_labels = {}\n",
    "        for node in G.nodes():\n",
    "            label = _neighborhood_aggregate(G, node, labels, edge_attr=edge_attr)\n",
    "            new_labels[node] = _hash_label(label, digest_size)\n",
    "        return new_labels\n",
    "\n",
    "    # set initial node labels\n",
    "    node_labels = _init_node_labels(G, edge_attr, node_attr)\n",
    "\n",
    "    subgraph_hash_counts = []\n",
    "    for _ in range(iterations):\n",
    "        node_labels = weisfeiler_lehman_step(G, node_labels, edge_attr=edge_attr)\n",
    "        counter = Counter(node_labels.values())\n",
    "        # sort the counter, extend total counts\n",
    "        subgraph_hash_counts.extend(sorted(counter.items(), key=lambda x: x[0]))\n",
    "\n",
    "    # hash the final counter\n",
    "    return _hash_label(str(tuple(subgraph_hash_counts)), digest_size)\n",
    "\n",
    "# Define a function to convert a SMILES string to a NetworkX graph\n",
    "# Apply Weisfeiler-Lehman hashing to each molecule graph\n",
    "# Convert molecules to NetworkX graphs\n",
    "# Calculate Weisfeiler-Lehman hash for each molecule graph\n",
    "# Convert Weisfeiler-Lehman hashes to a numerical representation\n",
    "# Perform K-means clustering\n",
    "from sklearn.cluster import KMeans\n",
    "n_clusters = 2  #number of clusters\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "# cluster_labels = kmeans.fit_predict(X_numerical)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
