{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc5349c2",
   "metadata": {},
   "source": [
    "# 1.Graph classification task\n",
    "# Dataset: Molecular_Sample.csv\n",
    "\n",
    "### 1.1. Extract graph features with eigenvector centrality, Katz centrality, Laplacian centrality\n",
    "### 1.2.Train model (SVM/MLP) with graph features as concatenation of above graph features,  with test_size = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26838d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.25\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from rdkit import Chem\n",
    "from sklearn.model_selection import train_test_split\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"./data/Molecular_Sample.csv\")\n",
    "\n",
    "# Preprocess the data\n",
    "graphs = []\n",
    "for smile in data['smiles']:\n",
    "    mol = Chem.MolFromSmiles(smile)\n",
    "    if mol is not None:\n",
    "        graph = Chem.rdmolops.GetAdjacencyMatrix(mol)\n",
    "        graphs.append(graph)\n",
    "\n",
    "# Extract node features (eigenvector centrality, Katz centrality, Laplacian centrality)\n",
    "node_features = []\n",
    "for graph in graphs:\n",
    "    G = nx.from_numpy_array(graph)\n",
    "    eigenvector_centrality = list(nx.eigenvector_centrality_numpy(G).values())\n",
    "    katz_centrality = list(nx.katz_centrality_numpy(G).values())\n",
    "    laplacian_centrality = list(nx.laplacian_centrality(G).values())\n",
    "    features = np.column_stack((eigenvector_centrality, katz_centrality, laplacian_centrality))\n",
    "    node_features.append(features)\n",
    "\n",
    "# Aggregate node features (sum)\n",
    "aggregated_features = [np.sum(features, axis=0) for features in node_features]\n",
    "\n",
    "# Reshape the input arrays\n",
    "X_train, X_test, y_train, y_test = train_test_split(aggregated_features, data['p_np'], test_size=0.3, random_state=42)\n",
    "X_train_reshaped = np.array(X_train).reshape(-1, 3)  # 3 centrality features\n",
    "X_test_reshaped = np.array(X_test).reshape(-1, 3)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_reshaped)\n",
    "X_test_scaled = scaler.transform(X_test_reshaped)\n",
    "\n",
    "# Train SVM classifier\n",
    "clf = svm.SVC(kernel='sigmoid')\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = clf.score(X_test_scaled, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39514b8",
   "metadata": {},
   "source": [
    "# 2. Graph classification task\n",
    "# Dataset: Molecular_Sample.csv\n",
    "\n",
    "### Train model (SVM/MLP) with graph features as graphlet kernel from practice code W7 with test_size = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3de1d8b",
   "metadata": {},
   "source": [
    "### Graphlet Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b3fc515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "def compute_graphlet_counts(G, k):\n",
    "    \"\"\"\n",
    "    Compute the counts of k-node graphlets in the given graph.\n",
    "\n",
    "    Parameters:\n",
    "        G (networkx.Graph): The input graph.\n",
    "        k (int): The size of the graphlets to count.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the counts of k-node graphlets.\n",
    "    \"\"\"\n",
    "    graphlet_counts = {graphlet: 0 for graphlet in range(1, k+1)}\n",
    "\n",
    "    for node in G.nodes():\n",
    "    # Generate the induced subgraph with node and its neighbors\n",
    "        subgraph_nodes = [node] + list(G.neighbors(node))\n",
    "        subgraph = G.subgraph(subgraph_nodes)\n",
    "\n",
    "        # Count the occurrences of k-node graphlets in the subgraph\n",
    "        for graphlet_size in range(1, k+1):\n",
    "            for subgraph_nodes_subset in combinations(subgraph_nodes, graphlet_size):\n",
    "                if G.subgraph(subgraph_nodes_subset).number_of_nodes() == graphlet_size:\n",
    "                    graphlet_counts[graphlet_size] += 1\n",
    "\n",
    "    return graphlet_counts\n",
    "\n",
    "def compute_graphlet_kernel(G1, G2, k):\n",
    "    \"\"\"\n",
    "    Compute the graphlet kernel between two graphs.\n",
    "\n",
    "    Parameters:\n",
    "        G1 (networkx.Graph): The first input graph.\n",
    "        G2 (networkx.Graph): The second input graph.\n",
    "        k (int): The size of the graphlets to count.\n",
    "\n",
    "    Returns:\n",
    "        float: The similarity score between the two graphs.\n",
    "    \"\"\"\n",
    "    # Compute the counts of k-node graphlets in each graph\n",
    "    graphlet_counts_G1 = compute_graphlet_counts(G1, k)\n",
    "    graphlet_counts_G2 = compute_graphlet_counts(G2, k)\n",
    "\n",
    "    # Compute the kernel value by comparing the counts of graphlets\n",
    "    kernel_value = 0\n",
    "    for graphlet in range(1, k+1):\n",
    "        kernel_value += min(graphlet_counts_G1[graphlet], graphlet_counts_G2[graphlet])\n",
    "\n",
    "    return kernel_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "76404c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "def mol_to_nx_graph(mol):\n",
    "    \"\"\"\n",
    "    Convert RDKit molecule to NetworkX graph.\n",
    "\n",
    "    Parameters:\n",
    "        mol (RDKit molecule): The input molecule.\n",
    "\n",
    "    Returns:\n",
    "        networkx.Graph: The NetworkX graph representation of the molecule.\n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Add nodes for atoms\n",
    "    for atom in mol.GetAtoms():\n",
    "        G.add_node(atom.GetIdx(), atomic_num=atom.GetAtomicNum())\n",
    "\n",
    "    # Add edges for bonds\n",
    "    for bond in mol.GetBonds():\n",
    "        G.add_edge(bond.GetBeginAtomIdx(), bond.GetEndAtomIdx(), bond_type=bond.GetBondType())\n",
    "\n",
    "    return G\n",
    "\n",
    "# Load molecular dataset\n",
    "molecules = [\n",
    "    \"[Cl].CC(C)NCC(O)COc1cccc2ccccc12\",\n",
    "    \"C(=O)(OC(C)(C)C)CCCc1ccc(cc1)N(CCCl)CCCl\",\n",
    "    \"c1cccn2c1nc(c2)CCN\",\n",
    "    \"Cc1onc(c2ccccc2Cl)c1C(=O)N[C@H]3[C@H]4SC(C)(C)[C@@H](N4C3=O)C(O)=O\",\n",
    "    \"CCN1CCN(C(=O)N[C@@H](C(=O)N[C@H]2[C@H]3SCC(=C(N3C2=O)C(O)=O)CSc4nnnn4C)c5ccc(O)cc5)C(=O)C1=O\",\n",
    "    \"CN(C)[C@H]1[C@@H]2C[C@H]3C(=C(O)c4c(O)cccc4[C@@]3(C)O)C(=O)[C@]2(O)C(=O)\\C(=C(/O)NCN5CCCC5)C1=O\",\n",
    "    \"Cn1c2CCC(Cn3ccnc3C)C(=O)c2c4ccccc14\",\n",
    "    \"COc1ccc(cc1)[C@@H]2Sc3ccccc3N(CCN(C)C)C(=O)[C@@H]2OC(C)=O\",\n",
    "    \"NC(N)=NC(=O)c1nc(Cl)c(N)nc1N\",\n",
    "    \"OCC(C)(O)c1onc(c2ncn3c2CN(C)C(c4c3cccc4Cl)=O)n1\",\n",
    "    \"CC1=CN([C@H]2C[C@H](F)[C@@H](CO)O2)C(=O)NC1=O\",\n",
    "    \"CCC(=O)C(CC(C)N(C)C)(c1ccccc1)c2ccccc2\",\n",
    "    \"CCN1N=NN(CCN2CCC(CC2)(COC)N(C(=O)CC)c3ccccc3)C1=O\",\n",
    "    \"CN(C)C(=O)C(CCN1CCC(O)(CC1)c1ccc(Cl)cc1)(c1ccccc1)c1ccccc1\",\n",
    "    \"CN1C2CCC1CC(C2)OC(=O)[C@H](CO)c3ccccc3\",\n",
    "    \"COc1ccc(Cl)cc1C(=O)NCCc2ccc(cc2)[S](=O)(=O)NC(=O)NC3CCCCC3\",\n",
    "    \"Nc1nnc(c(N)n1)c2cccc(Cl)c2Cl\",\n",
    "    \"OC(C)(C)c1onc(c2ncn3c2CN(C)C(c4c3cccc4Cl)=O)n1\",\n",
    "    \"CC(=O)Oc1ccccc1C(O)=O\",\n",
    "    \"O=C1N=CN=C2NNC=C12\",\n",
    "    \"CCCCC[C@H](O)/C=C/[C@H]1[C@H](O)CC(=O)[C@@H]1CCCCCCC(O)=O\",\n",
    "    \"CN1C(=O)N(C)c2nc[nH]c2C1=O.CN3C(=O)N(C)c4nc[nH]c4C3=O.NCCN\",\n",
    "    \"CCCCc1oc2ccccc2c1C(=O)c3cc(I)c(OCCN(CC)CC)c(I)c3\",\n",
    "    \"O.O.O.CC1(C)S[C@@H]2[C@H](NC(=O)[C@H](N)c3ccc(O)cc3)C(=O)N2[C@H]1C(O)=O\",\n",
    "    \"CC1(C)S[C@@H]2[C@H](NC(=O)[C@H](N)c3ccccc3)C(=O)N2[C@H]1C(O)=O\",\n",
    "    \"C[C@]1(O)CC[C@H]2[C@@H]3CCC4=CC(=O)CC[C@]4(C)[C@H]3CC[C@]12C\"\n",
    "]\n",
    "\n",
    "# Convert molecules to NetworkX graphs\n",
    "molecule_graphs = [mol_to_nx_graph(Chem.MolFromSmiles(mol)) for mol in molecules]\n",
    "\n",
    "# Compute the graph kernel for all pairs of molecules\n",
    "num_molecules = len(molecule_graphs)\n",
    "graph_kernel_matrix = np.zeros((num_molecules, num_molecules))\n",
    "\n",
    "for i in range(num_molecules):\n",
    "    for j in range(num_molecules):\n",
    "        kernel_value = compute_graphlet_kernel(molecule_graphs[i], molecule_graphs[j], k)\n",
    "        graph_kernel_matrix[i, j] = kernel_value\n",
    "\n",
    "# print(\"Graph Kernel Matrix:\")\n",
    "# print(graph_kernel_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af4ed19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"./data/Molecular_Sample.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6c7fa64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Extracting the 'p_np' column as class labels\n",
    "class_labels = data['p_np'].tolist()\n",
    "\n",
    "# Split data into features (graph kernel matrix) and labels\n",
    "X = graph_kernel_matrix\n",
    "y = class_labels\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Train an SVM classifier\n",
    "clf = SVC(kernel='sigmoid')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ec098b",
   "metadata": {},
   "source": [
    "### Random walk kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "045a4c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "\n",
    "def random_walk_kernel(graph1, graph2, walk_length=2, num_walks=20):\n",
    "    # Initialize the kernel to zero\n",
    "    kernel = 0\n",
    "\n",
    "    # Perform random walks on both graphs\n",
    "    for _ in range(num_walks):\n",
    "        # Perform a random walk on the first graph\n",
    "        walk1 = random_walk(graph1, walk_length)\n",
    "\n",
    "        # Perform a random walk on the second graph\n",
    "        walk2 = random_walk(graph2, walk_length)\n",
    "\n",
    "        # Update the kernel if the walks have common subsequences\n",
    "        if walk1 == walk2:\n",
    "            kernel += 1\n",
    "\n",
    "    # Normalize the kernel\n",
    "    kernel /= num_walks\n",
    "\n",
    "    return kernel\n",
    "\n",
    "def random_walk(graph, walk_length):\n",
    "    # Start the walk at a random node\n",
    "    node = random.choice(list(graph.nodes()))\n",
    "\n",
    "    # Perform the random walk\n",
    "    walk = [node]\n",
    "    for _ in range(walk_length - 1):\n",
    "        neighbors = list(graph.neighbors(node))\n",
    "        if neighbors:\n",
    "            node = random.choice(neighbors)\n",
    "            walk.append(node)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return tuple(walk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c9cf08ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "\n",
    "# Define a function to convert a SMILES string to a NetworkX graph\n",
    "def smiles_to_nx_graph(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    G = nx.Graph()\n",
    "    for atom in mol.GetAtoms():\n",
    "        G.add_node(atom.GetIdx(), atomic_num=atom.GetAtomicNum())\n",
    "    for bond in mol.GetBonds():\n",
    "        G.add_edge(bond.GetBeginAtomIdx(), bond.GetEndAtomIdx())\n",
    "    return G\n",
    "\n",
    "# Define the molecular dataset\n",
    "molecules = [\n",
    "    \"[Cl].CC(C)NCC(O)COc1cccc2ccccc12\",\n",
    "    \"C(=O)(OC(C)(C)C)CCCc1ccc(cc1)N(CCCl)CCCl\",\n",
    "    \"c1cccn2c1nc(c2)CCN\",\n",
    "    \"Cc1onc(c2ccccc2Cl)c1C(=O)N[C@H]3[C@H]4SC(C)(C)[C@@H](N4C3=O)C(O)=O\",\n",
    "    \"CCN1CCN(C(=O)N[C@@H](C(=O)N[C@H]2[C@H]3SCC(=C(N3C2=O)C(O)=O)CSc4nnnn4C)c5ccc(O)cc5)C(=O)C1=O\",\n",
    "    \"CN(C)[C@H]1[C@@H]2C[C@H]3C(=C(O)c4c(O)cccc4[C@@]3(C)O)C(=O)[C@]2(O)C(=O)\\C(=C(/O)NCN5CCCC5)C1=O\",\n",
    "    \"Cn1c2CCC(Cn3ccnc3C)C(=O)c2c4ccccc14\",\n",
    "    \"COc1ccc(cc1)[C@@H]2Sc3ccccc3N(CCN(C)C)C(=O)[C@@H]2OC(C)=O\",\n",
    "    \"NC(N)=NC(=O)c1nc(Cl)c(N)nc1N\",\n",
    "    \"OCC(C)(O)c1onc(c2ncn3c2CN(C)C(c4c3cccc4Cl)=O)n1\",\n",
    "    \"CC1=CN([C@H]2C[C@H](F)[C@@H](CO)O2)C(=O)NC1=O\",\n",
    "    \"CCC(=O)C(CC(C)N(C)C)(c1ccccc1)c2ccccc2\",\n",
    "    \"CCN1N=NN(CCN2CCC(CC2)(COC)N(C(=O)CC)c3ccccc3)C1=O\",\n",
    "    \"CN(C)C(=O)C(CCN1CCC(O)(CC1)c1ccc(Cl)cc1)(c1ccccc1)c1ccccc1\",\n",
    "    \"CN1C2CCC1CC(C2)OC(=O)[C@H](CO)c3ccccc3\",\n",
    "    \"COc1ccc(Cl)cc1C(=O)NCCc2ccc(cc2)[S](=O)(=O)NC(=O)NC3CCCCC3\",\n",
    "    \"Nc1nnc(c(N)n1)c2cccc(Cl)c2Cl\",\n",
    "    \"OC(C)(C)c1onc(c2ncn3c2CN(C)C(c4c3cccc4Cl)=O)n1\",\n",
    "    \"CC(=O)Oc1ccccc1C(O)=O\",\n",
    "    \"O=C1N=CN=C2NNC=C12\",\n",
    "    \"CCCCC[C@H](O)/C=C/[C@H]1[C@H](O)CC(=O)[C@@H]1CCCCCCC(O)=O\",\n",
    "    \"CN1C(=O)N(C)c2nc[nH]c2C1=O.CN3C(=O)N(C)c4nc[nH]c4C3=O.NCCN\",\n",
    "    \"CCCCc1oc2ccccc2c1C(=O)c3cc(I)c(OCCN(CC)CC)c(I)c3\",\n",
    "    \"O.O.O.CC1(C)S[C@@H]2[C@H](NC(=O)[C@H](N)c3ccc(O)cc3)C(=O)N2[C@H]1C(O)=O\",\n",
    "    \"CC1(C)S[C@@H]2[C@H](NC(=O)[C@H](N)c3ccccc3)C(=O)N2[C@H]1C(O)=O\",\n",
    "    \"C[C@]1(O)CC[C@H]2[C@@H]3CCC4=CC(=O)CC[C@]4(C)[C@H]3CC[C@]12C\"\n",
    "]\n",
    "\n",
    "# Convert molecules to NetworkX graphs\n",
    "molecule_graphs = [smiles_to_nx_graph(mol) for mol in molecules]\n",
    "\n",
    "# Calculate the random walk kernel for all pairs of molecules\n",
    "num_molecules = len(molecule_graphs)\n",
    "random_walk_kernel_matrix = np.zeros((num_molecules, num_molecules))\n",
    "\n",
    "for i in range(num_molecules):\n",
    "    for j in range(num_molecules):\n",
    "        kernel_value = random_walk_kernel(molecule_graphs[i], molecule_graphs[j], walk_length=2, num_walks=20)\n",
    "        random_walk_kernel_matrix[i, j] = kernel_value\n",
    "\n",
    "# print(\"Random Walk Kernel Matrix:\")\n",
    "# print(random_walk_kernel_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a0205c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Extracting the 'p_np' column as class labels\n",
    "class_labels = data['p_np'].tolist()\n",
    "\n",
    "# Split data into features (graph kernel matrix) and labels\n",
    "X = random_walk_kernel_matrix\n",
    "y = class_labels\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Train an SVM classifier\n",
    "clf = SVC(kernel='sigmoid')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f75cdc",
   "metadata": {},
   "source": [
    "### Functions for hashing graphs to strings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "520f7244",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Functions for hashing graphs to strings.\n",
    "Isomorphic graphs should be assigned identical hashes.\n",
    "For now, only Weisfeiler-Lehman hashing is implemented.\n",
    "\"\"\"\n",
    "from hashlib import blake2b\n",
    "\n",
    "def _hash_label(label, digest_size):\n",
    "    return blake2b(label.encode(\"ascii\"), digest_size=digest_size).hexdigest()\n",
    "\n",
    "def _init_node_labels(G, edge_attr, node_attr):\n",
    "    if node_attr:\n",
    "        return {u: str(dd[node_attr]) for u, dd in G.nodes(data=True)}\n",
    "    elif edge_attr:\n",
    "        return {u: \"\" for u in G}\n",
    "    else:\n",
    "        return {u: str(deg) for u, deg in G.degree()}\n",
    "\n",
    "def _neighborhood_aggregate(G, node, node_labels, edge_attr=None):\n",
    "    \"\"\"\n",
    "    Compute new labels for given node by aggregating\n",
    "    the labels of each node's neighbors.\n",
    "    \"\"\"\n",
    "    label_list = []\n",
    "    for nbr in G.neighbors(node):\n",
    "        prefix = \"\" if edge_attr is None else str(G[node][nbr][edge_attr])\n",
    "        label_list.append(prefix + node_labels[nbr])\n",
    "    return node_labels[node] + \"\".join(sorted(label_list))\n",
    "\n",
    "def weisfeiler_lehman_graph_hash(\n",
    "    G, edge_attr=None, node_attr=None, iterations=3, digest_size=16\n",
    "):\n",
    "    def weisfeiler_lehman_step(G, labels, edge_attr=None):\n",
    "        \"\"\"\n",
    "        Apply neighborhood aggregation to each node\n",
    "        in the graph.\n",
    "        Computes a dictionary with labels for each node.\n",
    "        \"\"\"\n",
    "        new_labels = {}\n",
    "        for node in G.nodes():\n",
    "            label = _neighborhood_aggregate(G, node, labels, edge_attr=edge_attr)\n",
    "            new_labels[node] = _hash_label(label, digest_size)\n",
    "        return new_labels\n",
    "\n",
    "    # set initial node labels\n",
    "    node_labels = _init_node_labels(G, edge_attr, node_attr)\n",
    "\n",
    "    subgraph_hash_counts = []\n",
    "    for _ in range(iterations):\n",
    "        node_labels = weisfeiler_lehman_step(G, node_labels, edge_attr=edge_attr)\n",
    "        counter = Counter(node_labels.values())\n",
    "        # sort the counter, extend total counts\n",
    "        subgraph_hash_counts.extend(sorted(counter.items(), key=lambda x: x[0]))\n",
    "\n",
    "    # hash the final counter\n",
    "    return _hash_label(str(tuple(subgraph_hash_counts)), digest_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7c111a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weisfeiler-Lehman Hashes:\n",
      "Molecule 1: fdc62ba403815cbbad163e9a90e4f380\n",
      "Molecule 2: 59021053eebae767fb2ff217dfd62d2c\n",
      "Molecule 3: beabbf9aec01fa1dbaa3d6075d144fca\n",
      "Molecule 4: 0cb1970fabeb6965c279c9fae18bc172\n",
      "Molecule 5: 2f6f3a1d30ecb2ba14b02bf8cb2feeac\n",
      "Molecule 6: 2d2cde088a4e720162514658bf8af971\n",
      "Molecule 7: f1bce8e84ea37cd3f5df8a9e7b1e4019\n",
      "Molecule 8: 6efd18c0e56b5f45c3688340b24c3502\n",
      "Molecule 9: c0c9f1824297b949a1c9b9e31720b43c\n",
      "Molecule 10: d9437e4f1aa9171bfaa70513223d138f\n",
      "Molecule 11: 7b45a86e36ea37ff77cc1fdb034ccdf6\n",
      "Molecule 12: b28f416458ad4e13e10fbe112d214c05\n",
      "Molecule 13: 62b5e9fc8d97351407f8ad44456c2061\n",
      "Molecule 14: 63a41f239654874f2e05295d36ff4fd3\n",
      "Molecule 15: 9429dd492cf9667b8b31f9ac23841747\n",
      "Molecule 16: 4617a153bc030cf8c0f369be6a33da60\n",
      "Molecule 17: 104894c25635a1f8c2b98b48cf7e76f1\n",
      "Molecule 18: 548847041ddc78b5a5d5b5693d0d8765\n",
      "Molecule 19: b5c7c83ad619fb714b9b86891b4234ee\n",
      "Molecule 20: b795f1fa874b702a7ad46e4bd3020390\n",
      "Molecule 21: 044a966319483878653be582056ec3e5\n",
      "Molecule 22: dc01ea6528dbf36f53c30c8d5c932dfa\n",
      "Molecule 23: f0d832008a186a5116c6e7b22e819657\n",
      "Molecule 24: 1005b6ca23278a5fd630839cad00b4f5\n",
      "Molecule 25: f390ef3c431cdaae27032e0b76b51217\n",
      "Molecule 26: 410b54e90493830145c5c2fd96e5d574\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from rdkit import Chem\n",
    "\n",
    "# Define a function to convert a SMILES string to a NetworkX graph\n",
    "def smiles_to_nx_graph(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    G = nx.Graph()\n",
    "    for atom in mol.GetAtoms():\n",
    "        G.add_node(atom.GetIdx(), atomic_num=atom.GetAtomicNum())\n",
    "    for bond in mol.GetBonds():\n",
    "        G.add_edge(bond.GetBeginAtomIdx(), bond.GetEndAtomIdx())\n",
    "    return G\n",
    "\n",
    "# Apply Weisfeiler-Lehman hashing to each molecule graph\n",
    "def weisfeiler_lehman_for_molecules(molecule_graphs, edge_attr=None, node_attr=None, iterations=3, digest_size=16):\n",
    "    hashes = []\n",
    "    for graph in molecule_graphs:\n",
    "        graph_hash = weisfeiler_lehman_graph_hash(graph, edge_attr=edge_attr, node_attr=node_attr, iterations=iterations, digest_size=digest_size)\n",
    "        hashes.append(graph_hash)\n",
    "    return hashes\n",
    "\n",
    "# Convert molecules to NetworkX graphs\n",
    "molecule_graphs = [smiles_to_nx_graph(mol) for mol in molecules]\n",
    "\n",
    "# Calculate Weisfeiler-Lehman hash for each molecule graph\n",
    "wl_hashes = weisfeiler_lehman_for_molecules(molecule_graphs)\n",
    "\n",
    "print(\"Weisfeiler-Lehman Hashes:\")\n",
    "for i, hash_val in enumerate(wl_hashes):\n",
    "    print(f\"Molecule {i+1}: {hash_val}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "483e9ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Assignments:\n",
      "Molecule 1: Cluster 1\n",
      "Molecule 2: Cluster 0\n",
      "Molecule 3: Cluster 0\n",
      "Molecule 4: Cluster 1\n",
      "Molecule 5: Cluster 1\n",
      "Molecule 6: Cluster 1\n",
      "Molecule 7: Cluster 0\n",
      "Molecule 8: Cluster 0\n",
      "Molecule 9: Cluster 1\n",
      "Molecule 10: Cluster 0\n",
      "Molecule 11: Cluster 0\n",
      "Molecule 12: Cluster 0\n",
      "Molecule 13: Cluster 1\n",
      "Molecule 14: Cluster 0\n",
      "Molecule 15: Cluster 0\n",
      "Molecule 16: Cluster 1\n",
      "Molecule 17: Cluster 1\n",
      "Molecule 18: Cluster 0\n",
      "Molecule 19: Cluster 0\n",
      "Molecule 20: Cluster 1\n",
      "Molecule 21: Cluster 1\n",
      "Molecule 22: Cluster 0\n",
      "Molecule 23: Cluster 1\n",
      "Molecule 24: Cluster 1\n",
      "Molecule 25: Cluster 0\n",
      "Molecule 26: Cluster 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Convert Weisfeiler-Lehman hashes to a numerical representation\n",
    "X_numerical = np.array([[int(c, 16) for c in hash_val] for hash_val in wl_hashes])\n",
    "\n",
    "# Perform K-means clustering\n",
    "n_clusters = 2  #number of clusters\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(X_numerical)\n",
    "\n",
    "# Print cluster assignments\n",
    "print(\"Cluster Assignments:\")\n",
    "for i, label in enumerate(cluster_labels):\n",
    "    print(f\"Molecule {i+1}: Cluster {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b20840",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
